#!/usr/bin/env python3
"""
è°ƒè¯•è„šæœ¬ï¼šæ£€æŸ¥aloha_test_datasetçš„å®é™…æ•°æ®ç»“æ„
"""

import sys
import os
from pathlib import Path

# è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆä¸è®­ç»ƒè„šæœ¬ä¸€è‡´ï¼‰
os.environ['HF_HOME'] = '/era-ai/lm/dataset/huggingface'
os.environ['HF_CACHE_HOME'] = '/era-ai/lm/dataset/huggingface_cache'
os.environ['HF_DATASETS_CACHE'] = '/era-ai/lm/dataset/huggingface_cache/datasets'
os.environ['HF_LEROBOT_HOME'] = '/era-ai/lm/dataset/huggingface_cache/lerobot'

# æ·»åŠ è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / "ac_training"))

# åº”ç”¨PyAV patch
import lerobot.common.datasets.video_utils as video_utils
if not hasattr(video_utils, '_openpi_patched'):
    print("ğŸ”§ åº”ç”¨PyAV patch...")
    def patched_decode_video_frames(video_path, timestamps, tolerance_s, backend="pyav"):
        return video_utils.decode_video_frames_torchvision(video_path, timestamps, tolerance_s, backend="pyav")
    video_utils.decode_video_frames = patched_decode_video_frames
    video_utils._openpi_patched = True

from lerobot.common.datasets.lerobot_dataset import LeRobotDataset, LeRobotDatasetMetadata
from datasets import load_dataset

def debug_hf_dataset_directly():
    """ç›´æ¥è°ƒè¯•HuggingFaceæ•°æ®é›†ï¼Œä¸é€šè¿‡LeRobotåŒ…è£…"""
    print("ğŸ” æ­¥éª¤1: ç›´æ¥æ£€æŸ¥HuggingFaceæ•°æ®é›†...")
    
    try:
        # å°è¯•å¤šç§æ–¹å¼åŠ è½½æ•°æ®é›†
        dataset_paths = [
            'aloha_test_dataset',
            '/era-ai/lm/dataset/huggingface_cache/lerobot/aloha_test_dataset',
            '/era-ai/lm/dataset/huggingface/datasets/aloha_test_dataset'
        ]
        
        dataset = None
        for path in dataset_paths:
            try:
                print(f"  å°è¯•è·¯å¾„: {path}")
                dataset = load_dataset(path, split='train')
                print(f"  âœ… æˆåŠŸåŠ è½½: {path}")
                break
            except Exception as e:
                print(f"  âŒ å¤±è´¥: {e}")
        
        if dataset is None:
            print("âŒ æ‰€æœ‰è·¯å¾„éƒ½å¤±è´¥ï¼Œå°è¯•æ£€æŸ¥ç¼“å­˜ç›®å½•")
            return
        
        print(f"\nğŸ“Š æ•°æ®é›†åŸºæœ¬ä¿¡æ¯:")
        print(f"  é•¿åº¦: {len(dataset)}")
        print(f"  åˆ—å: {dataset.column_names}")
        
        # æ£€æŸ¥æ˜¯å¦ç¼ºå°‘å¿…è¦çš„åˆ—
        required_columns = ['timestamp', 'action', 'observation.state']
        missing_columns = [col for col in required_columns if col not in dataset.column_names]
        print(f"  ç¼ºå°‘çš„å¿…è¦åˆ—: {missing_columns}")
        
        # è¯¦ç»†æ£€æŸ¥ç°æœ‰åˆ—
        print(f"\nğŸ” è¯¦ç»†æ£€æŸ¥ç°æœ‰åˆ—:")
        for col_name in dataset.column_names:
            col_data = dataset[col_name]
            print(f"  {col_name}:")
            print(f"    ç±»å‹: {type(col_data)}")
            print(f"    é•¿åº¦: {len(col_data)}")
            
            # æ£€æŸ¥å‰å‡ ä¸ªå…ƒç´ 
            try:
                first_few = [col_data[i] for i in range(min(3, len(col_data)))]
                print(f"    å‰3ä¸ªå…ƒç´ ç±»å‹: {[type(x) for x in first_few]}")
                for i, elem in enumerate(first_few):
                    if hasattr(elem, 'shape'):
                        print(f"      [{i}] shape: {elem.shape}")
                    elif hasattr(elem, '__len__') and not isinstance(elem, str):
                        print(f"      [{i}] length: {len(elem)}")
                    print(f"      [{i}] sample: {str(elem)[:100]}...")
            except Exception as e:
                print(f"    è®¿é—®å…ƒç´ å¤±è´¥: {e}")
        
        return dataset  # è¿”å›æ•°æ®é›†ä¾›åç»­ä½¿ç”¨
        
        # å°è¯•ä¸åŒçš„è®¿é—®æ–¹å¼
        print(f"\nğŸ” å°è¯•ä¸åŒçš„timestampè®¿é—®æ–¹å¼:")
        try:
            # æ–¹å¼1: ç›´æ¥ç´¢å¼•
            ts_0 = timestamp_col[0]
            print(f"  timestamp[0]: {type(ts_0)} = {ts_0}")
        except Exception as e:
            print(f"  timestamp[0] å¤±è´¥: {e}")
        
        try:
            # æ–¹å¼2: è½¬æ¢ä¸ºåˆ—è¡¨
            ts_list = list(timestamp_col)
            print(f"  list(timestamp): é•¿åº¦={len(ts_list)}, å‰3ä¸ª={ts_list[:3]}")
            print(f"  listå…ƒç´ ç±»å‹: {[type(x) for x in ts_list[:3]]}")
        except Exception as e:
            print(f"  list(timestamp) å¤±è´¥: {e}")
        
        try:
            # æ–¹å¼3: è½¬æ¢ä¸ºnumpy
            import numpy as np
            ts_np = np.array(timestamp_col)
            print(f"  np.array(timestamp): {ts_np.shape} {ts_np.dtype}")
        except Exception as e:
            print(f"  np.array(timestamp) å¤±è´¥: {e}")
        
        try:
            # æ–¹å¼4: è½¬æ¢ä¸ºtorch tensor
            import torch
            ts_torch = torch.tensor(list(timestamp_col))
            print(f"  torch.tensor(list(timestamp)): {ts_torch.shape} {ts_torch.dtype}")
        except Exception as e:
            print(f"  torch.tensorè½¬æ¢å¤±è´¥: {e}")
        
        # æ£€æŸ¥ç¬¬ä¸€è¡Œå®Œæ•´æ•°æ®
        print(f"\nğŸ“‹ ç¬¬ä¸€è¡Œå®Œæ•´æ•°æ®:")
        first_row = dataset[0]
        for key, value in first_row.items():
            print(f"  {key}: {type(value)}")
            if hasattr(value, 'shape'):
                print(f"    shape: {value.shape}")
            elif isinstance(value, (list, tuple)):
                print(f"    length: {len(value)}")
            print(f"    sample: {str(value)[:100]}...")
            
    except Exception as e:
        print(f"âŒ HFæ•°æ®é›†æ£€æŸ¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def test_torch_stack_with_column():
    """æµ‹è¯•torch.stackä¸Columnå¯¹è±¡çš„äº¤äº’"""
    print("\nğŸ” æ­¥éª¤2: æµ‹è¯•torch.stackä¸Columnå¯¹è±¡...")
    
    try:
        dataset = load_dataset('/era-ai/lm/dataset/huggingface_cache/lerobot/aloha_test_dataset', split='train')
        
        # æ‰¾åˆ°ä»»ä½•ä¸€ä¸ªæ•°å€¼åˆ—è¿›è¡Œæµ‹è¯•ï¼ˆå› ä¸ºæˆ‘ä»¬ç°åœ¨çŸ¥é“æ²¡æœ‰timestampåˆ—ï¼‰
        column_name = dataset.column_names[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨åˆ—
        col_data = dataset[column_name]
        
        print(f"æµ‹è¯•åˆ—: {column_name}")
        print(f"  åˆ—ç±»å‹: {type(col_data)}")
        print(f"  åˆ—çš„__class__: {col_data.__class__}")
        print(f"  åˆ—çš„æ¨¡å—: {col_data.__class__.__module__}")
        print(f"  æ˜¯å¦æ˜¯Column: {'Column' in col_data.__class__.__name__}")
        
        # è¯¦ç»†æ£€æŸ¥Columnå¯¹è±¡çš„å±æ€§
        print(f"\nğŸ” Columnå¯¹è±¡è¯¦ç»†ä¿¡æ¯:")
        print(f"  dir(col_data): {[attr for attr in dir(col_data) if not attr.startswith('_')]}")
        
        # æ£€æŸ¥å‰å‡ ä¸ªå…ƒç´ 
        print(f"\nğŸ” åˆ—æ•°æ®æ ·æœ¬:")
        for i in range(min(3, len(col_data))):
            elem = col_data[i]
            print(f"  [{i}]: {type(elem)} = {str(elem)[:100]}...")
        
        # å°è¯•torch.stack
        print(f"\nğŸ” å°è¯•torch.stack(col_data):")
        import torch
        try:
            result = torch.stack(col_data)
            print(f"  âœ… ç›´æ¥stackæˆåŠŸ! ç»“æœ: {type(result)}, shape: {result.shape}")
        except Exception as e:
            print(f"  âŒ ç›´æ¥stackå¤±è´¥: {e}")
            print(f"  é”™è¯¯ç±»å‹: {type(e)}")
            
            # å°è¯•å„ç§è½¬æ¢æ–¹æ³•
            print(f"\nğŸ”§ å°è¯•ä¿®å¤æ–¹æ³•:")
            
            # æ–¹æ³•1: è½¬æ¢ä¸ºåˆ—è¡¨å†stack
            try:
                list_data = list(col_data)
                print(f"  list(col_data): é•¿åº¦={len(list_data)}, å‰3ä¸ªç±»å‹={[type(x) for x in list_data[:3]]}")
                tensor_list = [torch.as_tensor(item) for item in list_data]
                result1 = torch.stack(tensor_list)
                print(f"  âœ… æ–¹æ³•1æˆåŠŸ: list->tensor_list->stack, shape: {result1.shape}")
                return True
            except Exception as e1:
                print(f"  âŒ æ–¹æ³•1å¤±è´¥: {e1}")
            
            # æ–¹æ³•2: ç›´æ¥è½¬æ¢Column
            try:
                result2 = torch.as_tensor(col_data)
                print(f"  âœ… æ–¹æ³•2æˆåŠŸ: torch.as_tensor(column), shape: {result2.shape}")
                return True
            except Exception as e2:
                print(f"  âŒ æ–¹æ³•2å¤±è´¥: {e2}")
            
            # æ–¹æ³•3: æ£€æŸ¥Columnæ˜¯å¦æœ‰ç‰¹æ®Šæ–¹æ³•
            if hasattr(col_data, 'to_pylist'):
                try:
                    pylist = col_data.to_pylist()
                    result3 = torch.stack([torch.as_tensor(x) for x in pylist])
                    print(f"  âœ… æ–¹æ³•3æˆåŠŸ: to_pylist->stack, shape: {result3.shape}")
                    return True
                except Exception as e3:
                    print(f"  âŒ æ–¹æ³•3å¤±è´¥: {e3}")
        
        return False
        
    except Exception as e:
        print(f"âŒ æ•´ä½“æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_torch_stack_patch():
    """æµ‹è¯•torch.stackçš„patchä¿®å¤"""
    print("\nğŸ” æ­¥éª¤3: æµ‹è¯•torch.stack patchä¿®å¤...")
    
    # åº”ç”¨patch
    import torch
    if not hasattr(torch, '_debug_patch_applied'):
        print("ğŸ”§ åº”ç”¨torch.stack Columnå…¼å®¹æ€§patch...")
        original_stack = torch.stack
        
        def patched_stack(tensors, dim=0, *, out=None):
            print(f"  [PATCH] torch.stackè°ƒç”¨, è¾“å…¥ç±»å‹: {type(tensors)}")
            if hasattr(tensors, '__class__'):
                print(f"  [PATCH] è¾“å…¥ç±»å: {tensors.__class__.__name__}")
                print(f"  [PATCH] è¾“å…¥æ¨¡å—: {tensors.__class__.__module__}")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯HF Datasetçš„Columnå¯¹è±¡
            if hasattr(tensors, '__class__') and 'Column' in tensors.__class__.__name__:
                print(f"  [PATCH] æ£€æµ‹åˆ°Columnå¯¹è±¡ï¼Œè¿›è¡Œè½¬æ¢...")
                # å°è¯•è½¬æ¢ä¸ºtensoråˆ—è¡¨
                try:
                    tensor_list = [torch.as_tensor(item) for item in tensors]
                    print(f"  [PATCH] è½¬æ¢æˆåŠŸ: {len(tensor_list)}ä¸ªtensor")
                    return original_stack(tensor_list, dim=dim, out=out)
                except Exception as e:
                    print(f"  [PATCH] è½¬æ¢å¤±è´¥: {e}")
                    raise e
            else:
                print(f"  [PATCH] æ­£å¸¸tensorï¼Œç›´æ¥è°ƒç”¨åŸå§‹stack")
                return original_stack(tensors, dim=dim, out=out)
        
        torch.stack = patched_stack
        torch._debug_patch_applied = True
        print("âœ… Patchåº”ç”¨å®Œæˆ")
    
    # é‡æ–°æµ‹è¯•Columnå¯¹è±¡
    print("\nğŸ”§ é‡æ–°æµ‹è¯•Columnå¯¹è±¡å¤„ç†:")
    success = test_torch_stack_with_column()
    return success

def test_lerobot_dataset_with_patch():
    """ä½¿ç”¨patchæµ‹è¯•LeRobotDatasetåˆ›å»º"""
    print("\nğŸ” æ­¥éª¤4: ä½¿ç”¨patchæµ‹è¯•LeRobotDataset...")
    
    try:
        dataset = LeRobotDataset('aloha_test_dataset', skip_problematic_episodes=True)
        print(f"âœ… LeRobotDatasetåˆ›å»ºæˆåŠŸ!")
        print(f"  æ•°æ®é›†é•¿åº¦: {len(dataset)}")
        
        # å°è¯•è·å–ä¸€ä¸ªæ ·æœ¬
        sample = dataset[0]
        print(f"âœ… æ ·æœ¬è·å–æˆåŠŸ!")
        print(f"  æ ·æœ¬é”®: {list(sample.keys())}")
        return True
        
    except Exception as e:
        print(f"âŒ LeRobotDatasetä»ç„¶å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    print("ğŸ” è¯¦ç»†è°ƒè¯•ALOHA Test Datasetçš„Columné—®é¢˜...")
    
    # æ­¥éª¤1: ç›´æ¥æ£€æŸ¥HFæ•°æ®é›†
    dataset = debug_hf_dataset_directly()
    
    # æ­¥éª¤2: æµ‹è¯•torch.stacké—®é¢˜
    original_success = test_torch_stack_with_column()
    
    # æ­¥éª¤3: æµ‹è¯•patchä¿®å¤
    patch_success = test_torch_stack_patch()
    
    # æ­¥éª¤4: æµ‹è¯•LeRobotDataset with patch
    lerobot_success = test_lerobot_dataset_with_patch()
    
    # æ€»ç»“
    print(f"\nğŸ“Š æµ‹è¯•æ€»ç»“:")
    print(f"  åŸå§‹torch.stack: {'âœ…' if original_success else 'âŒ'}")
    print(f"  Patchä¿®å¤æµ‹è¯•: {'âœ…' if patch_success else 'âŒ'}")
    print(f"  LeRobotDataset: {'âœ…' if lerobot_success else 'âŒ'}")
    
    if patch_success and lerobot_success:
        print(f"\nğŸ‰ ä¿®å¤éªŒè¯æˆåŠŸ! å¯ä»¥åº”ç”¨åˆ°è®­ç»ƒè„šæœ¬ä¸­")
    else:
        print(f"\nâš ï¸ ä¿®å¤éœ€è¦è¿›ä¸€æ­¥è°ƒæ•´")

if __name__ == "__main__":
    main()