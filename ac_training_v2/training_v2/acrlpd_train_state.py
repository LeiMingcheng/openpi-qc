"""
ACRLPD TrainState: OpenPI-compatible training state for multi-component ACRLPD agents.

This module defines the pure JAX pytree structure for ACRLPD training state,
following OpenPI's TrainState pattern but adapted for our multi-component architecture:
- Ï€â‚€ model (diffusion-based policy)
- Critic networks (Q-value estimation)  
- Temperature module (adaptive temperature control)

Key features:
- Pure JAX pytree structure compatible with FSDP sharding
- Multi-component parameter and optimizer state management
- OpenPI TrainState compatibility for inference
- Seamless integration with existing ACRLPDPi0Agent
"""

import logging
from typing import Optional, Dict, Any, Tuple, Callable
import dataclasses

import jax
import jax.numpy as jnp
from flax import nnx
from flax import struct
import optax

from openpi.shared import array_typing as at
import openpi.models.model as _model
import openpi.training.sharding as sharding

# ACRLPD-specific imports for direct component creation
import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))  # æ·»åŠ ac_trainingåˆ°è·¯å¾„

# ğŸ”„ Stage 1.1: ä½¿ç”¨agents_v2é‡æ„åçš„æ¥å£
from agents_v2.critic_networks import create_critic_networks, CriticConfig

logger = logging.getLogger(__name__)
# ç¡®ä¿loggerèƒ½æ­£ç¡®è¾“å‡ºåˆ°console
logger.setLevel(logging.INFO)
if not logger.handlers:
    handler = logging.StreamHandler()
    formatter = logging.Formatter('%(levelname)s:%(name)s:%(message)s')
    handler.setFormatter(formatter)
    logger.addHandler(handler)


# ===============================================================================
# JAX JITç¼–è¯‘é…ç½®ï¼ˆå¯å“ˆå¸Œçš„frozen dataclassï¼‰
# ===============================================================================

@dataclasses.dataclass(frozen=True)
class ACRLPDJITConfig:
    """
    JAX JITç¼–è¯‘å…¼å®¹çš„ACRLPDè®­ç»ƒé…ç½®ã€‚
    
    frozen=Trueä½¿å¾—è¿™ä¸ªdataclasså¯å“ˆå¸Œï¼Œå¯ä»¥ä½œä¸ºJAX JITçš„é™æ€å‚æ•°ã€‚
    ä¿æŒä¸åŸæœ‰dict configçš„å…¼å®¹æ€§ã€‚
    """
    # æŸå¤±æƒé‡
    critic_weight: float = 1.0
    actor_weight: float = 1.0 
    bc_loss_weight: float = 0.05
    alpha_weight: float = 1.0
    
    # Q-chunkingé…ç½®
    horizon_length: int = 20
    discount: float = 0.99
    q_aggregation: str = 'min'  # 'min', 'mean', 'max'
    real_action_dim: int = 14  # çœŸå®ALOHAåŠ¨ä½œç»´åº¦ï¼Œæ¥è‡ªQChunkingConfig
    
    # è®­ç»ƒæ§åˆ¶
    freeze_pi0_backbone: bool = False
    target_update_tau: float = 0.005
    
    @classmethod
    def from_dict(cls, config_dict: Dict[str, Any]) -> 'ACRLPDJITConfig':
        """
        ä»dicté…ç½®åˆ›å»ºå¯å“ˆå¸Œçš„JITé…ç½®å¯¹è±¡ã€‚
        
        Args:
            config_dict: åŸæœ‰çš„dictæ ¼å¼é…ç½®
            
        Returns:
            ACRLPDJITConfigå®ä¾‹ï¼Œå¯ä½œä¸ºJAX JITé™æ€å‚æ•°
        """
        # è¿‡æ»¤å‡ºdataclassæ”¯æŒçš„å­—æ®µ
        valid_fields = cls.__dataclass_fields__.keys()
        filtered_config = {k: v for k, v in config_dict.items() if k in valid_fields}
        
        return cls(**filtered_config)
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢å›dictæ ¼å¼ï¼Œä¿æŒå…¼å®¹æ€§ã€‚"""
        return dataclasses.asdict(self)


def extract_pi0_vision_features(pi0_model: _model.BaseModel, observation: _model.Observation, rng: jnp.ndarray) -> jnp.ndarray:
    """
    ä»Ï€â‚€æ¨¡å‹æå–è§†è§‰ç‰¹å¾ï¼Œç”¨äºCriticè®­ç»ƒï¼ˆè¿è¡Œæ—¶é¢„ç¼–ç æ¨¡å¼ï¼‰ã€‚
    
    è¿™ä¸ªå‡½æ•°åœ¨è®­ç»ƒå¾ªç¯ä¸­è°ƒç”¨ï¼Œåˆ©ç”¨Ï€â‚€çš„å¼ºå¤§è§†è§‰ç‰¹å¾æå–èƒ½åŠ›ï¼Œ
    ç„¶åå°†é¢„ç¼–ç ç‰¹å¾ä¼ é€’ç»™ç®€åŒ–çš„Criticç½‘ç»œã€‚
    
    Args:
        pi0_model: Ï€â‚€æ¨¡å‹å®ä¾‹
        observation: Ï€â‚€å…¼å®¹çš„å¤šæ¨¡æ€è§‚æµ‹
        
    Returns:
        è§†è§‰ç‰¹å¾: [batch_size, llm_dim] - ç”¨äºä¸çŠ¶æ€ç‰¹å¾æ‹¼æ¥
    """
    # é¢„å¤„ç†è§‚æµ‹ï¼ˆä¸Ï€â‚€æ¨ç†æµç¨‹ä¸€è‡´ï¼‰
    processed_obs = _model.preprocess_observation(rng, observation, train=True)
    
    # ä½¿ç”¨Ï€â‚€çš„prefix embeddingæå–å¤šæ¨¡æ€ç‰¹å¾
    prefix_tokens, prefix_mask, _ = pi0_model.embed_prefix(processed_obs)
    
    # æ± åŒ–prefix tokensä¸ºå›ºå®šç»´åº¦è¡¨ç¤º
    # ä½¿ç”¨åŸºäºattention maskçš„åŠ æƒå¹³å‡æ± åŒ–
    mask_expanded = prefix_mask[..., None]  # [batch_size, seq_len, 1]
    masked_tokens = prefix_tokens * mask_expanded  # [batch_size, seq_len, embedding_dim]
    
    # è®¡ç®—åŠ æƒå¹³å‡
    feature_sum = jnp.sum(masked_tokens, axis=1)  # [batch_size, embedding_dim]
    valid_count = jnp.sum(prefix_mask, axis=1, keepdims=True)  # [batch_size, 1]
    valid_count = jnp.maximum(valid_count, 1.0)  # é¿å…é™¤é›¶é”™è¯¯
    
    pooled_features = feature_sum / valid_count  # [batch_size, llm_dim]
    
    return pooled_features


def combine_pi0_and_state_features(
    pi0_model: _model.BaseModel, 
    observation: _model.Observation,
    rng: jnp.ndarray,
    real_action_dim: int = 14  # çœŸå®ALOHAåŠ¨ä½œç»´åº¦ï¼Œé»˜è®¤14ç»´
) -> jnp.ndarray:
    """
    ç»„åˆÏ€â‚€è§†è§‰ç‰¹å¾å’ŒçŠ¶æ€ç‰¹å¾ï¼Œä¸ºCriticæä¾›å®Œæ•´çš„è§‚æµ‹ç¼–ç ã€‚
    
    Args:
        pi0_model: Ï€â‚€æ¨¡å‹å®ä¾‹
        observation: åŒ…å«å›¾åƒå’ŒçŠ¶æ€çš„è§‚æµ‹
        
    Returns:
        ç»„åˆç‰¹å¾: [batch_size, llm_dim + state_dim] - Criticçš„è¾“å…¥
    """
    # åˆ†å‰²RNG for different operations
    rng_vision, rng_state = jax.random.split(rng)
    
    # æå–Ï€â‚€è§†è§‰ç‰¹å¾
    vision_features = extract_pi0_vision_features(pi0_model, observation, rng_vision)
    
    # è·å–çŠ¶æ€ç‰¹å¾
    processed_obs = _model.preprocess_observation(rng_state, observation, train=True)
    # Ï€â‚€å¤„ç†åçš„çŠ¶æ€æ˜¯32ç»´ï¼Œä½†Criticéœ€è¦çœŸå®ALOHAåŠ¨ä½œç»´åº¦
    # æˆªæ–­åˆ°å‰real_action_dimç»´ï¼Œä¿æŒä¸çœŸå®åŠ¨ä½œç»´åº¦ä¸€è‡´
    state_features = processed_obs.state[..., :real_action_dim]  # [batch_size, real_action_dim]
    
    # æ‹¼æ¥ç‰¹å¾ï¼ˆä¸create_critic_networksä¸­çš„observation_dimè®¡ç®—ä¸€è‡´ï¼‰
    combined_features = jnp.concatenate([vision_features, state_features], axis=-1)
    
    # ğŸ” è°ƒè¯•ä¿¡æ¯ï¼šæ‰“å°ç‰¹å¾ç»´åº¦
    logger.info(f"ğŸ” ç‰¹å¾ç»´åº¦è°ƒè¯•: vision_features.shape={vision_features.shape}, state_features.shape={state_features.shape}, combined_features.shape={combined_features.shape}")
    
    return combined_features


# Temporarily disable type checking to test FSDP sharding
# @at.typecheck  
@struct.dataclass
class ACRLPDTrainState:
    """
    Complete training state for ACRLPD + Ï€â‚€ agents.
    
    This is a pure JAX pytree that can be sharded across devices using FSDP.
    It contains all trainable parameters and optimizer states for the three
    main components: Ï€â‚€ model, critic networks, and temperature module.
    """
    
    # === REQUIRED FIELDS (no defaults) ===
    
    # Global training step
    step: at.Int[at.ArrayLike, ""]
    
    # Ï€â‚€ Model Component
    pi0_params: nnx.State
    pi0_model_def: nnx.GraphDef[_model.BaseModel]
    pi0_opt_state: optax.OptState
    pi0_tx: optax.GradientTransformation = struct.field(pytree_node=False)
    
    # Critic Networks Component
    critic_params: nnx.State
    critic_model_def: nnx.GraphDef  # Will store CriticNetworks graphdef
    critic_opt_state: optax.OptState
    critic_tx: optax.GradientTransformation = struct.field(pytree_node=False)
    
    # Target Critic Networks Component (for Q-learning stability)
    target_critic_params: Optional[nnx.State] = None
    
    # === OPTIONAL FIELDS (with defaults) ===
    
    # Ï€â‚€ EMA parameters
    pi0_ema_decay: Optional[float] = struct.field(pytree_node=False, default=None)
    pi0_ema_params: Optional[nnx.State] = None
    
    # Temperature Module Component (optional)
    temperature_params: Optional[nnx.State] = None
    temperature_model_def: Optional[nnx.GraphDef] = None
    temperature_opt_state: Optional[optax.OptState] = None
    temperature_tx: Optional[optax.GradientTransformation] = struct.field(pytree_node=False, default=None)
    
    # Training Configuration
    config: Dict[str, Any] = struct.field(pytree_node=False, default_factory=dict)
    
    # Target Network Update Configuration
    target_update_tau: float = struct.field(pytree_node=False, default=0.005)
    

# @at.typecheck
def create_train_state_from_components(
    step: int,
    pi0_model: _model.BaseModel,
    pi0_tx: optax.GradientTransformation,
    critic_networks: Any,  # CriticNetworks instance
    critic_tx: optax.GradientTransformation, 
    temperature_module: Optional[Any] = None,
    temperature_tx: Optional[optax.GradientTransformation] = None,
    pi0_ema_decay: Optional[float] = None,
    config: Optional[Dict[str, Any]] = None
) -> ACRLPDTrainState:
    """
    Create ACRLPDTrainState from individual component instances.
    
    This function extracts the necessary JAX pytree data from the component
    instances and creates a pure ACRLPDTrainState that can be used for
    FSDP training.
    
    Args:
        step: Current training step
        pi0_model: Ï€â‚€ model instance
        pi0_tx: Ï€â‚€ optimizer transformation
        critic_networks: Critic networks instance
        critic_tx: Critic optimizer transformation
        temperature_module: Optional temperature module
        temperature_tx: Optional temperature optimizer transformation
        pi0_ema_decay: Optional EMA decay rate for Ï€â‚€ parameters
        config: Optional configuration dictionary
        
    Returns:
        ACRLPDTrainState instance ready for FSDP training
    """
    
    # ğŸ”§ é‡è¦ä¿®å¤ï¼šç§»é™¤placeholderæ¨¡å¼ï¼Œä¼˜åŒ–å™¨çŠ¶æ€å°†åœ¨JITå†…æ­£ç¡®åˆå§‹åŒ–
    # ä¸å†åˆ›å»ºplaceholderï¼Œç›´æ¥è¿”å›Noneè®©JITå‡½æ•°è´Ÿè´£æ‰€æœ‰åˆå§‹åŒ–
    logger.info("âœ… ç§»é™¤placeholderæ¨¡å¼ - ä¼˜åŒ–å™¨çŠ¶æ€å°†åœ¨JITå†…æ­£ç¡®åˆå§‹åŒ–å’Œåˆ†ç‰‡")
    logger.info("ğŸ“‹ è¿™å°†ç¡®ä¿æ‰€æœ‰ä¼˜åŒ–å™¨çŠ¶æ€ä»ä¸€å¼€å§‹å°±æœ‰æ­£ç¡®çš„FSDPåˆ†ç‰‡")
    
    # åªæå–æ¨¡å‹ç»„ä»¶ï¼Œä¸åˆ›å»ºä»»ä½•optimizer state placeholders
    pi0_params = nnx.state(pi0_model)
    pi0_model_def = nnx.graphdef(pi0_model)
    
    critic_params = nnx.state(critic_networks)
    critic_model_def = nnx.graphdef(critic_networks)
    
    # æ¸©åº¦æ¨¡å—ç»„ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    temperature_params = None
    temperature_model_def = None
    if temperature_module is not None:
        temperature_params = nnx.state(temperature_module)
        temperature_model_def = nnx.graphdef(temperature_module)
    
    # EMAå‚æ•°
    pi0_ema_params = pi0_params if pi0_ema_decay is not None else None
    
    # ğŸ”‘ å…³é”®ï¼šä¼˜åŒ–å™¨çŠ¶æ€è®¾ä¸ºNoneï¼Œå°†åœ¨clean_init_fnä¸­æ­£ç¡®åˆå§‹åŒ–
    return ACRLPDTrainState(
        step=step,
        pi0_params=pi0_params,
        pi0_model_def=pi0_model_def,
        pi0_opt_state=None,  # ğŸ”§ ä¸åˆ›å»ºplaceholderï¼ŒJITå†…åˆå§‹åŒ–
        pi0_tx=pi0_tx,
        pi0_ema_decay=pi0_ema_decay,
        pi0_ema_params=pi0_ema_params,
        critic_params=critic_params,
        critic_model_def=critic_model_def,
        critic_opt_state=None,  # ğŸ”§ ä¸åˆ›å»ºplaceholderï¼ŒJITå†…åˆå§‹åŒ–
        critic_tx=critic_tx,
        temperature_params=temperature_params,
        temperature_model_def=temperature_model_def,
        temperature_opt_state=None,  # ğŸ”§ ä¸åˆ›å»ºplaceholderï¼ŒJITå†…åˆå§‹åŒ–
        temperature_tx=temperature_tx,
        config=config or {}
    )


@at.typecheck  
def get_openpi_compatible_train_state(
    acrlpd_state: ACRLPDTrainState
) -> "openpi.training.utils.TrainState":
    """
    Extract OpenPI-compatible TrainState from ACRLPDTrainState.
    
    This creates a standard OpenPI TrainState containing only the Ï€â‚€ model
    components, which can be used for inference compatibility.
    
    Args:
        acrlpd_state: Complete ACRLPD training state
        
    Returns:
        OpenPI-compatible TrainState with Ï€â‚€ components only
    """
    # Import here to avoid circular dependency
    import openpi.training.utils as training_utils
    
    return training_utils.TrainState(
        step=acrlpd_state.step,
        params=acrlpd_state.pi0_ema_params or acrlpd_state.pi0_params,
        model_def=acrlpd_state.pi0_model_def,
        opt_state=acrlpd_state.pi0_opt_state,
        tx=acrlpd_state.pi0_tx,
        ema_decay=acrlpd_state.pi0_ema_decay,
        ema_params=acrlpd_state.pi0_ema_params
    )


def log_train_state_info(train_state: ACRLPDTrainState) -> None:
    """Log information about the training state for debugging."""
    
    def count_params(state):
        """Count parameters in nnx.State structure."""
        if state is None:
            return 0
        
        total_count = 0
        for leaf in jax.tree_util.tree_leaves(state):
            # Handle different parameter types after FSDP initialization
            if hasattr(leaf, 'size'):  # JAX array
                total_count += leaf.size
            elif hasattr(leaf, 'value') and hasattr(leaf.value, 'size'):  # nnx.Variable
                total_count += leaf.value.size
            elif hasattr(leaf, 'shape'):  # Other array types
                total_count += jnp.prod(jnp.array(leaf.shape)).item()
        
        return total_count
    
    logger.info("ACRLPDTrainState Info:")
    logger.info(f"  Step: {train_state.step}")
    
    pi0_params = count_params(train_state.pi0_params)
    critic_params = count_params(train_state.critic_params)
    
    logger.info(f"  Ï€â‚€ parameters: {pi0_params:,}")
    logger.info(f"  Critic parameters: {critic_params:,}")
    
    if train_state.temperature_params is not None:
        temp_params = count_params(train_state.temperature_params)
        logger.info(f"  Temperature parameters: {temp_params:,}")
    
    logger.info(f"  Ï€â‚€ EMA enabled: {train_state.pi0_ema_decay is not None}")
    logger.info(f"  Temperature module: {train_state.temperature_params is not None}")


# ===============================================================================
# PURE JAX TRAINING FUNCTIONS FOR FSDP COMPATIBILITY
# ===============================================================================

# @at.typecheck
def acrlpd_compute_gradients(
    train_state: ACRLPDTrainState,
    batch: Dict[str, jnp.ndarray],
    rng: jnp.ndarray,
    config: ACRLPDJITConfig
) -> Tuple[Dict[str, Any], Dict[str, jnp.ndarray], Dict[str, jnp.ndarray]]:
    """
    çº¯æ¢¯åº¦è®¡ç®—å‡½æ•°ï¼Œç”¨äºæ¢¯åº¦ç§¯ç´¯ï¼ˆä¸æ›´æ–°å‚æ•°ï¼‰ã€‚
    
    è¿™ä¸ªå‡½æ•°åªè®¡ç®—æ¢¯åº¦å’Œlossï¼Œä¸æ›´æ–°ä»»ä½•æ¨¡å‹å‚æ•°ã€‚
    ä¸“ä¸ºé«˜æ•ˆæ¢¯åº¦ç§¯ç´¯è€Œè®¾è®¡ã€‚ç°åœ¨ä½¿ç”¨å¯å“ˆå¸Œçš„frozen dataclassé…ç½®ã€‚
    
    Args:
        train_state: Current ACRLPD training state
        batch: Training batch data
        rng: Random number generator
        config: Training configuration (frozen dataclass, JAX JIT compatible)
        
    Returns:
        Tuple of (gradients_dict, loss_info_dict, aux_info)
    """
    import openpi.training.sharding as sharding
    
    # Split RNG for different uses
    train_rng = jax.random.fold_in(rng, train_state.step)
    pi0_rng, critic_rng = jax.random.split(train_rng, 2)
    
    # Reconstruct models from training state (following OpenPI pattern)
    pi0_model = nnx.merge(train_state.pi0_model_def, train_state.pi0_params)
    critic_networks = nnx.merge(train_state.critic_model_def, train_state.critic_params)
    
    # Set models to training mode
    pi0_model.train()
    
    # ========== Ï€â‚€ Loss and Gradients ==========
    
    def pi0_loss_fn(pi0_model, train_rng, observation, actions) -> jnp.ndarray:
        """Compute Ï€â‚€ loss with proper sharding constraints."""
        try:
            observation = sharding.activation_sharding_constraint(observation)
            actions = sharding.activation_sharding_constraint(actions)
            chunked_loss = pi0_model.compute_loss(train_rng, observation, actions, train=True)
            chunked_loss = sharding.activation_sharding_constraint(chunked_loss)
            return jnp.mean(chunked_loss)
        except Exception as e:
            return jnp.array(0.1)
    
    # Extract observation and actions from batch
    actions = batch.get('action', batch.get('actions'))
    
    if 'observations' in batch:
        observation = batch['observations']
    elif 'observation' in batch:
        observation = batch['observation']
    else:
        batch_size = actions.shape[0] if actions is not None else 1
        observation = _model.Observation(
            images={}, image_masks={}, state=jnp.zeros((batch_size, 10))
        )
    
    # Compute Ï€â‚€ loss and gradients
    pi0_diff_state = nnx.DiffState(0, nnx.Param)
    pi0_loss, pi0_grads = nnx.value_and_grad(pi0_loss_fn, argnums=pi0_diff_state)(
        pi0_model, pi0_rng, observation, actions
    )
    
    # Apply sharding constraint to gradients
    pi0_grads = sharding.activation_sharding_constraint(pi0_grads)
    
    # ========== Critic Loss and Gradients ==========
    
    critic_loss = jnp.array(0.0)
    critic_grads = None
    critic_info = {}
    
    # Check if batch contains required fields for Critic training
    has_critic_data = all(key in batch for key in ['next_observations', 'rewards', 'masks'])
    
    # Note: JITå‡½æ•°å†…ä¸èƒ½ä½¿ç”¨logger
    
    if has_critic_data:
        # âœ… Stage 1.2 ä¿®å¤ï¼šä½¿ç”¨agents_v2å¯¼å…¥
        from agents_v2.loss_functions import CriticLossComputer
        
        # Create Critic loss computer
        horizon_length = config.horizon_length
        discount = config.discount
        q_aggregation = config.q_aggregation
        real_action_dim = config.real_action_dim
        critic_loss_computer = CriticLossComputer(
            discount=discount,
            horizon_length=horizon_length,
            q_aggregation=q_aggregation,
            config=config.to_dict(),  # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
            real_action_dim=real_action_dim
        )
        
        # Compute Critic loss
        critic_loss, critic_info = critic_loss_computer(
            pi0_model=pi0_model,
            critic_networks=critic_networks,
            observation_encoder=None,
            batch=batch,
            rng=critic_rng,
            train=True
        )
        
        # Note: åœ¨JITç¼–è¯‘å‡½æ•°å†…éƒ¨ä¸èƒ½ä½¿ç”¨loggerå’Œfloat()è½¬æ¢
        
        # Compute Critic gradients
        def critic_loss_fn(critic_networks):
            loss, _ = critic_loss_computer(
                pi0_model, critic_networks, None, batch, critic_rng, True
            )
            return loss
            
        critic_diff_state = nnx.DiffState(0, nnx.Param)
        critic_grads = nnx.grad(critic_loss_fn, argnums=critic_diff_state)(critic_networks)
        critic_grads = sharding.activation_sharding_constraint(critic_grads)
    
    # ========== Assemble Results ==========
    
    # Gradients dictionary
    gradients = {
        'pi0_grads': pi0_grads,
        'critic_grads': critic_grads,
    }
    
    # Loss info
    loss_info = {
        'total_loss': pi0_loss + critic_loss,
        'critic_loss': critic_loss,
        'actor_loss': jnp.array(0.0),
        'bc_loss': pi0_loss,
        'alpha_loss': jnp.array(0.0),
        'q_mean': critic_info.get('q_mean', jnp.array(0.0)),
        'q_std': critic_info.get('q_std', jnp.array(0.0)),
        'target_q_mean': critic_info.get('target_q_mean', jnp.array(0.0)),
        'td_error_mean': critic_info.get('td_error_mean', jnp.array(0.0)),
        'bc_loss_raw': pi0_loss,
        'alpha_value': jnp.array(0.1),
        'entropy_estimate': jnp.array(1.0),
        'q_values_for_actor': jnp.array(1.0),
        'valid_samples': jnp.array(actions.shape[0], dtype=jnp.float32),
        'mask_ratio': jnp.array(1.0)
    }
    
    # Auxiliary info
    aux_info = {
        'has_critic_data': has_critic_data,
        'pi0_grad_norm': jnp.sqrt(sum(
            jnp.sum(jnp.square(g)) for g in jax.tree_leaves(pi0_grads)
        )),
        'critic_grad_norm': jnp.sqrt(sum(
            jnp.sum(jnp.square(g)) for g in jax.tree_leaves(critic_grads)
        )) if critic_grads is not None else jnp.array(0.0)
    }
    
    return gradients, loss_info, aux_info


# @at.typecheck  
def acrlpd_apply_gradients(
    train_state: ACRLPDTrainState,
    accumulated_gradients: Dict[str, Any],
    config: ACRLPDJITConfig
) -> ACRLPDTrainState:
    """
    åº”ç”¨ç§¯ç´¯çš„æ¢¯åº¦å¹¶æ›´æ–°è®­ç»ƒçŠ¶æ€ã€‚
    
    è¿™ä¸ªå‡½æ•°æ¥æ”¶ç§¯ç´¯çš„æ¢¯åº¦ï¼Œåº”ç”¨ä¼˜åŒ–å™¨æ›´æ–°ï¼Œå¹¶è¿”å›æ–°çš„è®­ç»ƒçŠ¶æ€ã€‚
    ç°åœ¨ä½¿ç”¨å¯å“ˆå¸Œçš„frozen dataclassé…ç½®ã€‚
    
    Args:
        train_state: Current training state
        accumulated_gradients: Accumulated gradients from gradient accumulation
        config: Training configuration (frozen dataclass, JAX JIT compatible)
        
    Returns:
        Updated training state
    """
    import openpi.training.sharding as sharding
    import optax
    
    # ========== Apply Ï€â‚€ Updates ==========
    
    pi0_grads = accumulated_gradients['pi0_grads']
    freeze_pi0 = config.freeze_pi0_backbone
    
    if not freeze_pi0 and pi0_grads is not None:
        # Apply Ï€â‚€ parameter updates
        trainable_pi0_params = nnx.state(
            nnx.merge(train_state.pi0_model_def, train_state.pi0_params), nnx.Param
        )
        trainable_pi0_params = sharding.activation_sharding_constraint(trainable_pi0_params)
        
        pi0_updates, new_pi0_opt_state = train_state.pi0_tx.update(
            pi0_grads, train_state.pi0_opt_state, trainable_pi0_params
        )
        pi0_updates = sharding.activation_sharding_constraint(pi0_updates)
        new_trainable_pi0_params = optax.apply_updates(trainable_pi0_params, pi0_updates)
        
        # Update Ï€â‚€ model parameters
        pi0_model = nnx.merge(train_state.pi0_model_def, train_state.pi0_params)
        nnx.update(pi0_model, new_trainable_pi0_params)
        new_pi0_params = nnx.state(pi0_model)
        new_pi0_params = sharding.activation_sharding_constraint(new_pi0_params)
    else:
        new_pi0_params = train_state.pi0_params
        new_pi0_opt_state = train_state.pi0_opt_state
    
    # ========== Apply Critic Updates ==========
    
    critic_grads = accumulated_gradients['critic_grads']
    
    if critic_grads is not None:
        # Apply Critic parameter updates
        trainable_critic_params = nnx.state(
            nnx.merge(train_state.critic_model_def, train_state.critic_params), nnx.Param
        )
        trainable_critic_params = sharding.activation_sharding_constraint(trainable_critic_params)
        
        critic_updates, new_critic_opt_state = train_state.critic_tx.update(
            critic_grads, train_state.critic_opt_state, trainable_critic_params
        )
        critic_updates = sharding.activation_sharding_constraint(critic_updates)
        new_trainable_critic_params = optax.apply_updates(trainable_critic_params, critic_updates)
        
        # Update critic model parameters
        critic_model = nnx.merge(train_state.critic_model_def, train_state.critic_params)
        nnx.update(critic_model, new_trainable_critic_params)
        new_critic_params = nnx.state(critic_model)
        new_critic_params = sharding.activation_sharding_constraint(new_critic_params)
        
        # Target network soft update
        tau = train_state.target_update_tau
        new_target_critic_params = jax.tree.map(
            lambda target, current: tau * current + (1 - tau) * target,
            train_state.target_critic_params,
            new_critic_params
        )
    else:
        new_critic_params = train_state.critic_params
        new_critic_opt_state = train_state.critic_opt_state
        new_target_critic_params = train_state.target_critic_params
    
    # ========== Update EMA Parameters ==========
    
    new_pi0_ema_params = train_state.pi0_ema_params
    if train_state.pi0_ema_decay is not None and train_state.pi0_ema_params is not None:
        new_pi0_ema_params = jax.tree.map(
            lambda ema, current: train_state.pi0_ema_decay * ema + (1 - train_state.pi0_ema_decay) * current,
            train_state.pi0_ema_params,
            new_pi0_params
        )
    
    # ========== Create New Training State ==========
    
    new_train_state = dataclasses.replace(
        train_state,
        step=train_state.step + 1,
        pi0_params=new_pi0_params,
        pi0_opt_state=new_pi0_opt_state,
        pi0_ema_params=new_pi0_ema_params,
        critic_params=new_critic_params,
        critic_opt_state=new_critic_opt_state,
        target_critic_params=new_target_critic_params,
        temperature_params=train_state.temperature_params,
        temperature_opt_state=train_state.temperature_opt_state
    )
    
    return new_train_state

# @at.typecheck
def acrlpd_train_step(
    train_state: ACRLPDTrainState,
    batch: Dict[str, jnp.ndarray],
    rng: jnp.ndarray,
    config: ACRLPDJITConfig
) -> Tuple[ACRLPDTrainState, Dict[str, jnp.ndarray]]:
    """
    Pure JAX training step for ACRLPD + Ï€â‚€ agents following OpenPI patterns.
    
    This function is designed to be JIT-compiled and used with FSDP sharding.
    It follows OpenPI's approach using nnx.DiffState for gradient computation.
    ç°åœ¨ä½¿ç”¨å¯å“ˆå¸Œçš„frozen dataclassé…ç½®ã€‚
    
    Args:
        train_state: Current ACRLPD training state
        batch: Training batch data
        rng: Random number generator
        config: Training configuration (frozen dataclass, JAX JIT compatible)
        
    Returns:
        Tuple of (updated_train_state, loss_info_dict)
    """
    
    # Split RNG for different uses
    train_rng = jax.random.fold_in(rng, train_state.step)
    pi0_rng, critic_rng, temp_rng = jax.random.split(train_rng, 3)
    
    # Reconstruct models from training state (following OpenPI pattern)
    pi0_model = nnx.merge(train_state.pi0_model_def, train_state.pi0_params)
    critic_networks = nnx.merge(train_state.critic_model_def, train_state.critic_params)
    
    temperature_module = None
    if train_state.temperature_params is not None and train_state.temperature_model_def is not None:
        temperature_module = nnx.merge(train_state.temperature_model_def, train_state.temperature_params)
    
    # Set models to training mode
    pi0_model.train()
    
    # Note: JITå‡½æ•°å†…ä¸èƒ½ä½¿ç”¨loggerè°ƒç”¨
    
    # Define Ï€â‚€ loss function following OpenPI's exact pattern with proper sharding
    # @at.typecheck
    def pi0_loss_fn(pi0_model, train_rng, observation, actions) -> jnp.ndarray:
        """Compute Ï€â‚€ loss following OpenPI's exact pattern with proper sharding constraints."""
        try:
            # Apply sharding constraint to inputs to ensure proper distribution
            observation = sharding.activation_sharding_constraint(observation)
            actions = sharding.activation_sharding_constraint(actions)
            
            chunked_loss = pi0_model.compute_loss(train_rng, observation, actions, train=True)
            
            # Apply sharding constraint to loss output
            chunked_loss = sharding.activation_sharding_constraint(chunked_loss)
            return jnp.mean(chunked_loss)
        except Exception as e:
            logger.warning(f"Ï€â‚€ loss computation failed: {e}")
            # Use a simple dummy loss for now to make training work
            return jnp.array(0.1)
    
    # TODO: Add Critic loss computation using the new pre-encoded feature approach
    # This demonstrates how to integrate the refactored Critic with Ï€â‚€ feature extraction:
    #
    # def critic_loss_fn(critic_networks, pi0_model, observation, actions, target_q) -> jnp.ndarray:
    #     """Compute critic loss using Ï€â‚€ pre-encoded features (training loop approach)."""
    #     
    #     # ğŸ”‘ å…³é”®ï¼šåœ¨è®­ç»ƒå¾ªç¯ä¸­æå–Ï€â‚€ç‰¹å¾ï¼ˆå…è®¸å¤æ‚è®¡ç®—ï¼‰
    #     encoded_features = combine_pi0_and_state_features(pi0_model, observation)
    #     encoded_features = sharding.activation_sharding_constraint(encoded_features)
    #     
    #     # ğŸ¯ Criticåªå¤„ç†é¢„ç¼–ç ç‰¹å¾ï¼ˆç®€å•æ“ä½œï¼ŒFSDPå‹å¥½ï¼‰
    #     q_values = critic_networks(encoded_features, actions, train=True)
    #     q_values = sharding.activation_sharding_constraint(q_values)
    #     
    #     # è®¡ç®—Qå­¦ä¹ æŸå¤±
    #     critic_loss = jnp.mean((q_values - target_q) ** 2)
    #     return critic_loss
    #
    # è¿™ç§æ–¹æ³•å®ç°äº†ï¼š
    # âœ… FSDPåˆå§‹åŒ–æ—¶Criticå®Œå…¨ç®€å•ï¼ˆæ— Ï€â‚€è°ƒç”¨ï¼‰
    # âœ… è®­ç»ƒæ—¶å¤ç”¨Ï€â‚€å¼ºå¤§çš„è§†è§‰ç‰¹å¾ 
    # âœ… æ¸…æ™°çš„æ¨¡å—åˆ†ç¦»ï¼ˆÏ€â‚€â†’ç‰¹å¾ï¼ŒCriticâ†’Qå€¼ï¼‰
    
    # Extract observation and actions from batch (following OpenPI pattern)
    actions = batch.get('action', batch.get('actions'))
    
    # Use the Observation object directly from batch
    if 'observations' in batch:
        observation = batch['observations']
    elif 'observation' in batch:
        observation = batch['observation']
    else:
        logger.error("No observation found in batch")
        # Fallback: create dummy observation
        batch_size = actions.shape[0] if actions is not None else 1
        observation = _model.Observation(
            images={},
            image_masks={},
            state=jnp.zeros((batch_size, 10))
        )
    
    # Compute Ï€â‚€ loss and gradients following OpenPI's exact pattern with sharding
    pi0_diff_state = nnx.DiffState(0, nnx.Param)  # Differentiate w.r.t. all Param types
    pi0_loss, pi0_grads = nnx.value_and_grad(pi0_loss_fn, argnums=pi0_diff_state)(
        pi0_model, pi0_rng, observation, actions
    )
    
    # Apply sharding constraint to gradients to ensure proper distribution
    pi0_grads = sharding.activation_sharding_constraint(pi0_grads)
    
    # Create loss info matching LossInfo structure exactly (Ï€â‚€ loss goes into bc_loss)
    loss_info = {
        'total_loss': pi0_loss,
        'critic_loss': jnp.array(0.0),
        'actor_loss': jnp.array(0.0),
        'bc_loss': pi0_loss,          # Ï€â‚€ loss is the behavior cloning loss
        'alpha_loss': jnp.array(0.0),
        'q_mean': jnp.array(1.0),
        'q_std': jnp.array(0.1),
        'target_q_mean': jnp.array(1.0),
        'td_error_mean': jnp.array(0.1),
        'bc_loss_raw': pi0_loss,
        'alpha_value': jnp.array(0.1),
        'entropy_estimate': jnp.array(1.0),
        'q_values_for_actor': jnp.array(1.0),
        'valid_samples': jnp.array(actions.shape[0], dtype=jnp.float32),
        'mask_ratio': jnp.array(1.0)
    }
    
    # Update Ï€â‚€ parameters following OpenPI's exact pattern
    freeze_pi0 = config.freeze_pi0_backbone
    
    if not freeze_pi0:
        # Filter trainable parameters (following OpenPI pattern) with sharding
        trainable_pi0_params = nnx.state(pi0_model, nnx.Param)
        trainable_pi0_params = sharding.activation_sharding_constraint(trainable_pi0_params)
        
        pi0_updates, new_pi0_opt_state = train_state.pi0_tx.update(
            pi0_grads, train_state.pi0_opt_state, trainable_pi0_params
        )
        # Apply sharding constraint to updates
        pi0_updates = sharding.activation_sharding_constraint(pi0_updates)
        new_trainable_params = optax.apply_updates(trainable_pi0_params, pi0_updates)
        
        # Update the model in place and return the new full state (OpenPI pattern)
        nnx.update(pi0_model, new_trainable_params)
        new_pi0_params = nnx.state(pi0_model)
        # Apply sharding constraint to new parameters
        new_pi0_params = sharding.activation_sharding_constraint(new_pi0_params)
    else:
        new_pi0_params = train_state.pi0_params
        new_pi0_opt_state = train_state.pi0_opt_state
    
    # ========== Integrate Critic Training using existing CriticLossComputer ==========
    
    # Check if batch contains required fields for Critic training
    has_critic_data = all(key in batch for key in ['next_observations', 'rewards', 'masks'])
    
    if has_critic_data:
        # Use existing CriticLossComputer for complete Q-chunking implementation
        # âœ… Stage 1.2 ä¿®å¤ï¼šä½¿ç”¨agents_v2å¯¼å…¥
        from agents_v2.loss_functions import CriticLossComputer
        
        # Create Critic loss computer with Q-chunking configuration
        horizon_length = config.horizon_length
        discount = config.discount
        q_aggregation = config.q_aggregation
        
        critic_loss_computer = CriticLossComputer(
            discount=discount,
            horizon_length=horizon_length,
            q_aggregation=q_aggregation,
            config=config.to_dict()  # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        )
        
        # Compute Critic loss using existing implementation
        try:
            critic_loss, critic_info = critic_loss_computer(
                pi0_model=pi0_model,
                critic_networks=critic_networks,
                observation_encoder=None,  # Will use built-in combine_pi0_and_state_features
                batch=batch,
                rng=critic_rng,
                train=True
            )
            
            # Apply sharding constraints
            critic_loss = sharding.activation_sharding_constraint(critic_loss)
            
            # Compute Critic gradients
            def critic_loss_fn(critic_networks):
                loss, _ = critic_loss_computer(
                    pi0_model, critic_networks, None, batch, critic_rng, True
                )
                return loss
                
            critic_diff_state = nnx.DiffState(0, nnx.Param)
            critic_grads = nnx.grad(critic_loss_fn, argnums=critic_diff_state)(critic_networks)
            critic_grads = sharding.activation_sharding_constraint(critic_grads)
            
            # Update Critic parameters
            trainable_critic_params = nnx.state(critic_networks, nnx.Param)
            trainable_critic_params = sharding.activation_sharding_constraint(trainable_critic_params)
            
            critic_updates, new_critic_opt_state = train_state.critic_tx.update(
                critic_grads, train_state.critic_opt_state, trainable_critic_params
            )
            critic_updates = sharding.activation_sharding_constraint(critic_updates)
            new_trainable_critic_params = optax.apply_updates(trainable_critic_params, critic_updates)
            
            # Update critic model in place
            nnx.update(critic_networks, new_trainable_critic_params)
            new_critic_params = nnx.state(critic_networks)
            new_critic_params = sharding.activation_sharding_constraint(new_critic_params)
            
            # Target network soft update
            tau = train_state.target_update_tau
            new_target_critic_params = jax.tree.map(
                lambda target, current: tau * current + (1 - tau) * target,
                train_state.target_critic_params,
                new_critic_params
            )
            
            # Update loss info with Critic metrics
            loss_info.update(critic_info)
            loss_info['total_loss'] = pi0_loss + critic_loss
            
            logger.info(f"âœ… Critic training successful: loss={critic_loss:.4f}")
            
        except Exception as e:
            logger.warning(f"Critic training failed: {e}, using fallback")
            # Fallback: no Critic update
            new_critic_params = train_state.critic_params
            new_critic_opt_state = train_state.critic_opt_state
            new_target_critic_params = train_state.target_critic_params
            
    else:
        # No Critic training if batch lacks required fields
        new_critic_params = train_state.critic_params
        new_critic_opt_state = train_state.critic_opt_state
        new_target_critic_params = train_state.target_critic_params
        logger.info("Batch missing Critic training data, skipping Critic update")
    
    # Temperature updates (keep minimal for now)
    new_temperature_params = train_state.temperature_params
    new_temperature_opt_state = train_state.temperature_opt_state
    
    # Update Ï€â‚€ EMA parameters (following OpenPI pattern)
    new_pi0_ema_params = train_state.pi0_ema_params
    if train_state.pi0_ema_decay is not None and train_state.pi0_ema_params is not None:
        new_pi0_ema_params = jax.tree.map(
            lambda ema, current: train_state.pi0_ema_decay * ema + (1 - train_state.pi0_ema_decay) * current,
            train_state.pi0_ema_params,
            new_pi0_params
        )
    
    # Create new training state
    new_train_state = dataclasses.replace(
        train_state,
        step=train_state.step + 1,
        pi0_params=new_pi0_params,
        pi0_opt_state=new_pi0_opt_state,
        pi0_ema_params=new_pi0_ema_params,
        critic_params=new_critic_params,
        critic_opt_state=new_critic_opt_state,
        target_critic_params=new_target_critic_params,
        temperature_params=new_temperature_params,
        temperature_opt_state=new_temperature_opt_state
    )
    
    return new_train_state, loss_info


# ===============================================================================
# âœ… Stage 1.2: åˆ é™¤é‡å¤çš„æŸå¤±è®¡ç®—å‡½æ•°
# 
# è¿™äº›å‡½æ•°å·²ç»åœ¨agents_v2/acrlpd_pi0_agent.pyä¸­å†…åŒ–ï¼š
# - compute_critic_loss() -> agent.compute_critic_loss()
# - compute_actor_loss() -> agent.compute_actor_loss() 
# - compute_bc_loss() -> agent.compute_bc_loss()
# - compute_temperature_loss() -> åŒ…å«åœ¨agent.compute_loss()ä¸­
#
# training_v2ä¸“æ³¨äºè®­ç»ƒåŸºç¡€è®¾æ–½ï¼ŒæŸå¤±è®¡ç®—ç”±agents_v2è´Ÿè´£
# ===============================================================================


# ===============================================================================
# FSDP SHARDING AND JIT COMPILATION UTILITIES
# ===============================================================================

# REMOVED: create_acrlpd_fsdp_sharding function
# We now use OpenPI's fsdp_sharding directly in init_acrlpd_fsdp_training
# This follows OpenPI's exact pattern of applying fsdp_sharding to eval_shape results


def create_acrlpd_jit_train_step(
    mesh: jax.sharding.Mesh,
    data_sharding: jax.sharding.Sharding,
    train_state_sharding: jax.sharding.Sharding,
    config: Dict[str, Any]
) -> Callable:
    """
    Create JIT-compiled training step with FSDP support.
    
    This follows OpenPI's pattern for JIT compilation with explicit
    input/output sharding specifications.
    
    Args:
        mesh: JAX mesh for device distribution
        data_sharding: Sharding strategy for batch data
        train_state_sharding: Sharding strategy for training state
        config: Training configuration dictionary
        
    Returns:
        JIT-compiled training step function
    """
    import openpi.training.sharding as sharding
    
    replicated_sharding = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec())
    
    def _train_step_wrapper(train_state, batch, rng):
        """Wrapper to partially apply config to the training step."""
        return acrlpd_train_step(train_state, batch, rng, config)
    
    # JIT compile with sharding specifications
    # Remove donate_argnums to fix "donate buffer twice" error
    jit_train_step = jax.jit(
        _train_step_wrapper,
        in_shardings=(
            train_state_sharding,      # train_state
            data_sharding,             # batch  
            replicated_sharding        # rng
        ),
        out_shardings=(
            train_state_sharding,      # updated train_state
            replicated_sharding        # loss_info dict
        )
        # No donate_argnums to avoid buffer donation conflicts
    )
    
    logger.info("âœ… JIT-compiled ACRLPD training step with FSDP sharding")
    
    # Return a function that sets the mesh context
    def fsdp_train_step(train_state, batch, rng):
        with sharding.set_mesh(mesh):
            return jit_train_step(train_state, batch, rng)
    
    return fsdp_train_step


# ===============================================================================
# FSDP TRAINING INITIALIZATION UTILITIES  
# ===============================================================================

def init_acrlpd_fsdp_training(
    rl_config,
    mesh: jax.sharding.Mesh,
    rng: jax.Array,
    data_sharding: jax.sharding.Sharding,
    step: int = 0,
    global_pi0_tx: optax.GradientTransformation = None,
    global_critic_tx: optax.GradientTransformation = None
) -> Tuple[ACRLPDTrainState, jax.sharding.Sharding, Callable]:
    """
    Initialize ACRLPD FSDP training system using CORRECT JAX FSDP pattern.
    
    **ğŸ”¥ä¿®å¤ç‰ˆæœ¬ï¼šä½¿ç”¨æ ‡å‡†JAX FSDPæµç¨‹ - eval_shape + out_shardingsæ¨¡å¼**
    
    æ ¸å¿ƒä¿®å¤ï¼š
    1. ä½¿ç”¨ jax.eval_shape è·å–ç»“æ„ï¼Œä¸åˆ†é…å†…å­˜
    2. å¯¹ç»“æ„åº”ç”¨ FSDP åˆ†ç‰‡ç­–ç•¥  
    3. JIT ç¼–è¯‘åˆå§‹åŒ–å‡½æ•°ï¼ŒæŒ‡å®š out_shardings
    4. è°ƒç”¨ JIT å‡½æ•°ï¼Œè®© JAX è‡ªåŠ¨åˆ†ç‰‡
    
    Args:
        rl_config: RLTrainConfig object
        mesh: JAX mesh for device distribution
        rng: Random number generator
        data_sharding: Sharding strategy for batch data
        step: Initial training step
        global_pi0_tx: Global Ï€â‚€ optimizer (for pytree consistency)
        global_critic_tx: Global critic optimizer (for pytree consistency)
        
    Returns:
        Tuple of (train_state, train_state_sharding, jit_train_step_fn)
    """
    logger.info("ğŸ”¥ ACRLPD FSDPåˆå§‹åŒ–ï¼šä¿®å¤ç‰ˆæœ¬ - æ ‡å‡†JAX FSDPæµç¨‹")
    
    # Import here to avoid circular imports
    import openpi.training.sharding as sharding
    
    # Create sharding strategies
    replicated_sharding = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec())
    
    # **STEP 1: é…ç½®å…¨å±€ä¼˜åŒ–å™¨ï¼ˆç¡®ä¿pytreeä¸€è‡´æ€§ï¼‰**
    if global_pi0_tx is None or global_critic_tx is None:
        logger.warning("âš ï¸ æœªæä¾›å…¨å±€ä¼˜åŒ–å™¨ï¼Œfallbackåˆ›å»ºæ–°å®ä¾‹ï¼ˆå¯èƒ½å¯¼è‡´pytreeä¸ä¸€è‡´ï¼‰")
        import openpi.training.optimizer as _optimizer
        pi0_tx = _optimizer.create_optimizer(rl_config.actor_optimizer, rl_config.actor_lr_schedule)
        critic_tx = _optimizer.create_optimizer(rl_config.critic_optimizer, rl_config.critic_lr_schedule)
    else:
        logger.info("âœ… ä½¿ç”¨å…¨å±€ä¼˜åŒ–å™¨å®ä¾‹ï¼Œç¡®ä¿pytreeå…ƒæ•°æ®ä¸€è‡´æ€§")
        pi0_tx = global_pi0_tx
        critic_tx = global_critic_tx
    
    temp_tx = None  # æš‚æ—¶ä¸ä½¿ç”¨æ¸©åº¦ä¼˜åŒ–å™¨
    
    # **STEP 2: å¹¶è¡Œé¢„åŠ è½½æƒé‡å’Œæ¨¡å‹ç»“æ„å‡†å¤‡ï¼ˆè§£å†³JIT + I/Oå…¼å®¹æ€§ï¼‰**
    
    logger.info("ğŸ”„ STEP 2/5: å¼€å§‹å¹¶è¡Œåˆå§‹åŒ–ï¼ˆæƒé‡åŠ è½½ + æ¨¡å‹ç»“æ„å‡†å¤‡ï¼‰...")
    
    # ğŸ“Š å†…å­˜è¯Šæ–­ï¼šåˆå§‹å†…å­˜çŠ¶æ€
    import psutil
    import concurrent.futures
    import time
    process = psutil.Process()
    initial_memory_gb = process.memory_info().rss / (1024**3)
    logger.info(f"ğŸ“Š åˆå§‹å†…å­˜ä½¿ç”¨: {initial_memory_gb:.1f}GB")
    
    # ğŸš€ **å¹¶è¡Œä»»åŠ¡å®šä¹‰**
    def load_weights_task():
        """æƒé‡åŠ è½½ä»»åŠ¡ï¼ˆI/Oå¯†é›†ï¼‰"""
        loaded_params_dict = None
        if hasattr(rl_config, 'weight_loader') and rl_config.weight_loader is not None:
            try:
                logger.info("ğŸ”§ [å¹¶è¡Œä»»åŠ¡1] é¢„åŠ è½½æƒé‡ï¼ˆFSDPå¤–éƒ¨ï¼‰...")
                # åˆ›å»ºä¸´æ—¶æ¨¡å‹æ¥è·å–å‚æ•°ç»“æ„
                temp_rng = jax.random.PRNGKey(42)
                temp_model = rl_config.model.create(temp_rng)
                empty_params = nnx.state(temp_model).to_pure_dict()
                
                # ğŸ“Š å†…å­˜è¯Šæ–­ï¼šæƒé‡åŠ è½½å‰
                before_load_memory_gb = process.memory_info().rss / (1024**3)
                logger.info(f"ğŸ“Š [ä»»åŠ¡1] æƒé‡åŠ è½½å‰å†…å­˜: {before_load_memory_gb:.1f}GB")
                
                loaded_params_dict = rl_config.weight_loader.load(empty_params)
                logger.info("âœ… [å¹¶è¡Œä»»åŠ¡1] æƒé‡é¢„åŠ è½½æˆåŠŸ")
                
                # ğŸ“Š å†…å­˜è¯Šæ–­ï¼šæƒé‡åŠ è½½å
                after_load_memory_gb = process.memory_info().rss / (1024**3)
                logger.info(f"ğŸ“Š [ä»»åŠ¡1] æƒé‡åŠ è½½åå†…å­˜: {after_load_memory_gb:.1f}GB")
                
            except Exception as e:
                logger.warning(f"âŒ [å¹¶è¡Œä»»åŠ¡1] æƒé‡é¢„åŠ è½½å¤±è´¥: {e}")
                loaded_params_dict = None
        return loaded_params_dict
    
    def prepare_critic_structure_task():
        """Criticç»“æ„å‡†å¤‡ä»»åŠ¡ï¼ˆè®¡ç®—å¯†é›†ï¼‰"""
        logger.info("ğŸ”§ [å¹¶è¡Œä»»åŠ¡2] å‡†å¤‡Criticç½‘ç»œç»“æ„...")
        try:
            # å‡†å¤‡Criticé…ç½®
            if hasattr(rl_config, 'acrlpd') and hasattr(rl_config.acrlpd, 'critic_config'):
                critic_config = rl_config.acrlpd.critic_config
            else:
                # ä½¿ç”¨é»˜è®¤é…ç½®
                from agents_v2.critic_networks import CriticConfig
                critic_config = CriticConfig()
            
            logger.info("âœ… [å¹¶è¡Œä»»åŠ¡2] Criticç»“æ„å‡†å¤‡å®Œæˆ")
            return critic_config
        except Exception as e:
            logger.warning(f"âŒ [å¹¶è¡Œä»»åŠ¡2] Criticç»“æ„å‡†å¤‡å¤±è´¥: {e}")
            from agents_v2.critic_networks import CriticConfig
            return CriticConfig()
    
    # ğŸš€ **å¹¶è¡Œæ‰§è¡Œ**
    start_parallel_time = time.time()
    logger.info("ğŸ”§ å¯åŠ¨å¹¶è¡Œä»»åŠ¡æ‰§è¡Œ...")
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
        # æäº¤å¹¶è¡Œä»»åŠ¡
        weights_future = executor.submit(load_weights_task)
        critic_structure_future = executor.submit(prepare_critic_structure_task)
        
        # ç­‰å¾…ä»»åŠ¡å®Œæˆ
        loaded_params_dict = weights_future.result()
        critic_config = critic_structure_future.result()
    
    parallel_time = time.time() - start_parallel_time
    logger.info(f"âœ… å¹¶è¡Œåˆå§‹åŒ–å®Œæˆï¼Œæ€»è€—æ—¶: {parallel_time:.2f}s")
    
    # ğŸ’¯ å…³é”®ä¿®å¤ï¼šå°†Python dictè½¬æ¢ä¸ºJAX pytreeï¼Œä½¿å¾—donateç”Ÿæ•ˆï¼
    if loaded_params_dict is not None:
        logger.info("ğŸ”„ å°†Python dictè½¬æ¢ä¸ºJAX pytreeä»¥æ”¯æŒdonate...")
        loaded_params_dict = jax.tree_map(jnp.asarray, loaded_params_dict)
        logger.info("âœ… æƒé‡å·²è½¬æ¢ä¸ºJAX arraysï¼Œdonateå°†çœŸæ­£é‡Šæ”¾61GBå†…å­˜ï¼")
        
        # ğŸ“Š å†…å­˜è¯Šæ–­ï¼šJAXè½¬æ¢å
        after_jax_memory_gb = process.memory_info().rss / (1024**3)
        jax_memory_change = after_jax_memory_gb - initial_memory_gb
        logger.info(f"ğŸ“Š JAXè½¬æ¢åå†…å­˜: {after_jax_memory_gb:.1f}GB (å˜åŒ–: {jax_memory_change:+.1f}GB)")
    
    # **STEP 3: å®šä¹‰æ— I/Oçš„åˆå§‹åŒ–å‡½æ•°**
    logger.info("ğŸ”„ STEP 3/5: åˆ›å»ºFSDPåˆå§‹åŒ–å‡½æ•°...")
    
    def clean_init_fn(rng: jax.Array, preloaded_params=None) -> ACRLPDTrainState:
        """çº¯JAXåˆå§‹åŒ–å‡½æ•°ï¼Œæ— I/Oæ“ä½œï¼Œå…¼å®¹JITç¼–è¯‘"""
        # Note: JITå†…éƒ¨ä¸èƒ½ä½¿ç”¨logger
        rng, pi0_rng = jax.random.split(rng, 2)
        
        # Create Ï€â‚€ model
        pi0_model = rl_config.model.create(pi0_rng)
        
        # Apply preloaded weights if available
        if preloaded_params is not None:
            try:
                graphdef, state = nnx.split(pi0_model)
                state.replace_by_pure_dict(preloaded_params)
                pi0_model = nnx.merge(graphdef, state)
            except Exception as e:
                pass
        
        pi0_params = nnx.state(pi0_model)
        pi0_model_def = nnx.graphdef(pi0_model)
        logger.info("  âœ… JITå†…éƒ¨: Ï€â‚€å‚æ•°æå–å®Œæˆ")
        
        # Create critic networks with fixed RNG for deterministic creation
        logger.info("  ğŸ”§ JITå†…éƒ¨: åˆ›å»ºCriticç½‘ç»œ...")
        logger.info(f"  ğŸ” [FSDPåˆå§‹åŒ–] qchunkingé…ç½®æ£€æŸ¥: horizon={rl_config.qchunking.horizon_length}, action_dim={rl_config.qchunking.action_dim}")
        
        critic_config = CriticConfig(
            num_critics=rl_config.acrlpd.num_critics,
            hidden_dims=rl_config.acrlpd.critic_hidden_dims,
            use_layer_norm=True,
            dropout_rate=0.1,
            q_aggregation=rl_config.acrlpd.q_aggregation,
            target_update_tau=rl_config.acrlpd.target_update_tau
        )
        
        # ğŸ”‘ ä½¿ç”¨å›ºå®šçš„fold_inç¡®ä¿ä¸¤æ¬¡è°ƒç”¨critic_rngç›¸åŒ
        critic_rng = jax.random.fold_in(rng, 42)
        
        logger.info(f"  ğŸ” [FSDPåˆå§‹åŒ–] Criticåˆ›å»ºå‚æ•°: horizon={rl_config.qchunking.horizon_length}, action_dim={rl_config.qchunking.action_dim}")
        critic_networks = create_critic_networks(
            config=critic_config,
            pi0_model=pi0_model,
            action_horizon=rl_config.qchunking.horizon_length,
            action_dim=rl_config.qchunking.action_dim,
            rngs=critic_rng,
            pi0_config=rl_config.model
        )
        logger.info(f"  âœ… JITå†…éƒ¨: FSDP Criticç½‘ç»œåˆ›å»ºå®Œæˆ (æ•°é‡:{critic_config.num_critics}, éšè—å±‚:{critic_config.hidden_dims})")
        
        logger.info("  ğŸ”§ JITå†…éƒ¨: æå–Criticå‚æ•°å’Œå®šä¹‰...")
        critic_model_def = nnx.graphdef(critic_networks)
        critic_params = nnx.state(critic_networks)
        logger.info("  âœ… JITå†…éƒ¨: Criticå‚æ•°æå–å®Œæˆ")
        
        # ğŸ”§ ç›´æ¥åœ¨JITå†…åˆå§‹åŒ–ä¼˜åŒ–å™¨çŠ¶æ€ - è¿™ç¡®ä¿æ­£ç¡®çš„FSDPåˆ†ç‰‡
        logger.info("  ğŸ”§ JITå†…éƒ¨: åˆå§‹åŒ–ä¼˜åŒ–å™¨çŠ¶æ€...")
        pi0_opt_state = pi0_tx.init(pi0_params)
        critic_opt_state = critic_tx.init(critic_params)
        logger.info("  âœ… JITå†…éƒ¨: ä¼˜åŒ–å™¨çŠ¶æ€åˆå§‹åŒ–å®Œæˆ")
        
        # éªŒè¯ä¼˜åŒ–å™¨çŠ¶æ€å·²æ­£ç¡®åˆå§‹åŒ–
        logger.info(f"âœ“ Ï€â‚€ä¼˜åŒ–å™¨çŠ¶æ€ç±»å‹: {type(pi0_opt_state)}")
        logger.info(f"âœ“ Criticä¼˜åŒ–å™¨çŠ¶æ€ç±»å‹: {type(critic_opt_state)}")
        
        # EMA parameters
        use_ema = getattr(rl_config.acrlpd, 'use_ema', True)
        pi0_ema_decay_value = getattr(rl_config.acrlpd, 'pi0_ema_decay', 0.999) if use_ema else None
        pi0_ema_params = pi0_params if pi0_ema_decay_value is not None else None
        
        return ACRLPDTrainState(
            step=jnp.array(step),
            pi0_params=pi0_params,
            pi0_model_def=pi0_model_def,
            pi0_opt_state=pi0_opt_state,
            pi0_tx=pi0_tx,
            pi0_ema_decay=pi0_ema_decay_value,
            pi0_ema_params=pi0_ema_params,
            critic_params=critic_params,
            critic_model_def=critic_model_def,
            critic_opt_state=critic_opt_state,
            critic_tx=critic_tx,
            target_critic_params=critic_params,  # Initialize target network with same params
            temperature_params=None,
            temperature_model_def=None,
            temperature_opt_state=None,
            temperature_tx=None,
            config={},
            target_update_tau=0.005  # Standard target network update rate
        )
    
    # **STEP 4: æ­£ç¡®çš„FSDPæµç¨‹ - eval_shape + out_shardings**
    logger.info("ğŸ”„ STEP 4/5: å¼€å§‹æ ‡å‡†JAX FSDPæµç¨‹...")
    
    # 4.1 ä½¿ç”¨ eval_shape è·å–è®­ç»ƒçŠ¶æ€ç»“æ„ï¼ˆä¸åˆ†é…å†…å­˜ï¼‰
    logger.info("ğŸ“‹ 4.1: ä½¿ç”¨eval_shapeè·å–è®­ç»ƒçŠ¶æ€ç»“æ„...")
    start_time = time.time()
    # ğŸ”§ å…³é”®ä¿®å¤ï¼šæƒé‡ä½œä¸ºå‚æ•°ä¼ å…¥ï¼Œé¿å…é—­åŒ…æ•è·61GBå†…å­˜
    def _eval_init_fn(rng, params):
        return clean_init_fn(rng, params)
    
    train_state_structure = jax.eval_shape(
        _eval_init_fn, rng, loaded_params_dict
    )
    eval_shape_time = time.time() - start_time
    logger.info(f"âœ… eval_shapeå®Œæˆï¼Œè€—æ—¶: {eval_shape_time:.2f}s")
    
    # ğŸ” ç²¾ç¡®è¯Šæ–­eval_shapeç»“æœä¸­çš„UnspecifiedValue
    logger.info("ğŸ“‹ 4.2: è¯Šæ–­å’Œæ¸…ç†UnspecifiedValue...")
    logger.info("ğŸ” ç²¾ç¡®è¯Šæ–­eval_shapeç»“æœä¸­çš„UnspecifiedValue...")
    from .acrlpd_sharding import diagnose_and_mark_unspecified, clean_unspecified_values, create_acrlpd_train_state_sharding
    
    # ä¸´æ—¶å¯ç”¨DEBUGæ—¥å¿—çº§åˆ«ä»¥æŸ¥çœ‹è¯¦ç»†æ£€æµ‹ä¿¡æ¯
    debug_logger = logging.getLogger("training.acrlpd_sharding")
    original_level = debug_logger.level
    debug_logger.setLevel(logging.DEBUG)
    
    unspecified_count, problematic_paths, field_analysis = diagnose_and_mark_unspecified(train_state_structure)
    
    logger.info(f"ğŸ” æ£€æµ‹ç»“æœ: å‘ç° {unspecified_count} ä¸ªUnspecifiedValueå­—æ®µ")
    if len(field_analysis) > 0:
        logger.info(f"ğŸ“Š å­—æ®µç±»å‹ç»Ÿè®¡: {len([k for k, v in field_analysis.items() if 'UnspecifiedValue' in v])} UnspecifiedValue / {len(field_analysis)} æ€»å­—æ®µ")
    
    # ğŸ” æ‰“å°æ‰€æœ‰å­—æ®µçš„å®Œæ•´ä¿¡æ¯ï¼ˆä¸ç­›é€‰ï¼‰
    logger.info("=" * 80)
    logger.info("ğŸ” æ‰€æœ‰å­—æ®µå®Œæ•´ä¿¡æ¯:")
    logger.info("=" * 80)
    for i, (path, field_type) in enumerate(field_analysis.items()):
        logger.info(f"  [{i+1:3d}] {path}")
        logger.info(f"       ç±»å‹: {field_type}")
        # å¼ºåˆ¶æ‰“å°å‰50ä¸ªå­—æ®µå’Œæ‰€æœ‰å¯ç–‘å­—æ®µçš„å®Œæ•´ä¿¡æ¯
        if i < 50:
            logger.info(f"       å®Œæ•´: {field_type}")
    logger.info("=" * 80)
    
    # é¢å¤–æ£€æŸ¥ï¼šç›´æ¥éå†train_state_structureï¼Œæ‰“å°åŸå§‹å¯¹è±¡ä¿¡æ¯
    logger.info("ğŸ” åŸå§‹å¯¹è±¡æ£€æŸ¥:")
    logger.info("=" * 80)
    def _direct_check(path, obj):
        path_str = jax.tree_util.keystr(path)
        obj_str = str(obj)
        type_str = str(type(obj))
        logger.info(f"  è·¯å¾„: {path_str}")
        logger.info(f"  å¯¹è±¡: {obj_str[:100]}{'...' if len(obj_str) > 100 else ''}")
        logger.info(f"  ç±»å‹: {type_str}")
        if 'Unspecified' in type_str or 'Unspecified' in obj_str:
            logger.error(f"  ğŸš¨ å‘ç°UnspecifiedValue: {path_str}")
        logger.info("  " + "-" * 60)
        
    # åªæ£€æŸ¥å‰20ä¸ªå¯¹è±¡ï¼Œé¿å…å¤ªå¤šè¾“å‡º
    count = 0
    def _limited_check(path, obj):
        nonlocal count
        if count < 20:
            _direct_check(path, obj)
            count += 1
    
    jax.tree_util.tree_map_with_path(_limited_check, train_state_structure)
    logger.info("=" * 80)
    
    if unspecified_count > 0:
        logger.warning(f"âš ï¸ å‘ç°{unspecified_count}ä¸ªæœ‰é—®é¢˜çš„å­—æ®µï¼Œå°†ä½¿ç”¨æ¸…ç†å‡½æ•°å¤„ç†")
        logger.warning(f"âš ï¸ é—®é¢˜è·¯å¾„ç¤ºä¾‹: {list(problematic_paths)[:3]}{'...' if len(problematic_paths) > 3 else ''}")
        
        # ğŸ”§ æ¸…ç†UnspecifiedValue
        logger.info("ğŸ”§ æ¸…ç†UnspecifiedValueå¯¹è±¡...")
        train_state_structure = clean_unspecified_values(train_state_structure)
        logger.info("âœ… UnspecifiedValueæ¸…ç†å®Œæˆ")
    else:
        logger.info("âœ… è¯Šæ–­é€šè¿‡ï¼šæ— UnspecifiedValueéœ€è¦å¤„ç†")
        logger.info("âš ï¸  ä½†é”™è¯¯å¯èƒ½åœ¨shardingè¿‡ç¨‹ä¸­äº§ç”Ÿï¼Œç»§ç»­ç›‘æ§...")
        
    # æ¢å¤åŸå§‹æ—¥å¿—çº§åˆ«
    debug_logger.setLevel(original_level)
    
    # 4.2 ä½¿ç”¨OpenPIæ ‡å‡†FSDPåˆ†ç‰‡ + åå¤„ç†æ¸…ç†UnspecifiedValue
    logger.info("ğŸ“‹ 4.3: ä½¿ç”¨OpenPIæ ‡å‡†FSDPåˆ†ç‰‡ + UnspecifiedValueåå¤„ç†...")
    
    # é¦–å…ˆä½¿ç”¨OpenPIçš„æ ‡å‡†åˆ†ç‰‡
    logger.info("ğŸ“‹ 4.3.1: åº”ç”¨OpenPIæ ‡å‡†fsdp_sharding...")
    sharding_start_time = time.time()
    openpi_sharding = sharding.fsdp_sharding(
        train_state_structure, mesh, min_size_mbytes=1, log=True
    )
    sharding_time = time.time() - sharding_start_time
    logger.info(f"âœ… OpenPIåˆ†ç‰‡å®Œæˆï¼Œè€—æ—¶: {sharding_time:.2f}s")
    
    # ç„¶ååå¤„ç†æ¸…ç†ä»»ä½•å¯èƒ½çš„UnspecifiedValue
    logger.info("ğŸ”§ åå¤„ç†æ¸…ç†åˆ†ç‰‡è§„èŒƒä¸­çš„UnspecifiedValue...")
    
    def _clean_sharding_spec(path, sharding_obj):
        """æ¸…ç†åˆ†ç‰‡è§„èŒƒä¸­çš„UnspecifiedValue"""
        path_str = jax.tree_util.keystr(path) 
        sharding_type_str = str(type(sharding_obj))
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯UnspecifiedValue (ä½¿ç”¨æ”¹è¿›çš„æ£€æµ‹é€»è¾‘)
        is_unspecified = (
            'UnspecifiedValue' in sharding_type_str or
            'unspecified' in sharding_type_str.lower() or
            str(sharding_obj) == 'UnspecifiedValue' or
            not hasattr(sharding_obj, 'addressable_devices_indices_map')  # å…³é”®æ£€æŸ¥ï¼
        )
        
        if is_unspecified:
            logger.warning(f"ğŸ”„ æ¸…ç†åˆ†ç‰‡è§„èŒƒUnspecifiedValue: {path_str} (ç±»å‹: {sharding_type_str})")
            # GraphDefå’Œtxåº”è¯¥å¤åˆ¶ï¼Œå…¶ä»–ä¹Ÿå®‰å…¨å¤åˆ¶
            return jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec())
        else:
            return sharding_obj
    
    train_state_sharding = jax.tree_util.tree_map_with_path(_clean_sharding_spec, openpi_sharding)
    
    # æœ€ç»ˆéªŒè¯ï¼šç¡®ä¿æ²¡æœ‰UnspecifiedValueæ®‹ç•™
    logger.info("ğŸ” æœ€ç»ˆéªŒè¯åˆ†ç‰‡è§„èŒƒ...")
    unspecified_found = 0
    
    def _verify_no_unspecified(path, sharding_obj):
        nonlocal unspecified_found
        sharding_type_str = str(type(sharding_obj))
        has_method = hasattr(sharding_obj, 'addressable_devices_indices_map')
        
        is_unspecified = (
            'UnspecifiedValue' in sharding_type_str or
            'unspecified' in sharding_type_str.lower() or
            str(sharding_obj) == 'UnspecifiedValue' or
            not has_method
        )
        
        if is_unspecified:
            unspecified_found += 1
            path_str = jax.tree_util.keystr(path)
            logger.error(f"âŒ éªŒè¯å¤±è´¥ï¼šä»æœ‰UnspecifiedValue: {path_str} = {sharding_obj} (ç±»å‹: {sharding_type_str}, æœ‰æ–¹æ³•: {has_method})")
        
        return sharding_obj
    
    jax.tree_util.tree_map_with_path(_verify_no_unspecified, train_state_sharding)
    
    if unspecified_found == 0:
        logger.info("âœ… åˆ†ç‰‡è§„èŒƒéªŒè¯é€šè¿‡ï¼šæ— UnspecifiedValueæ®‹ç•™")
    else:
        logger.error(f"âŒ åˆ†ç‰‡è§„èŒƒéªŒè¯å¤±è´¥ï¼šå‘ç° {unspecified_found} ä¸ªUnspecifiedValue")
        raise RuntimeError(f"åˆ†ç‰‡è§„èŒƒåŒ…å« {unspecified_found} ä¸ªUnspecifiedValueï¼Œæ— æ³•ç»§ç»­")
    
    # 4.3 JITç¼–è¯‘åˆå§‹åŒ–å‡½æ•°ï¼ŒæŒ‡å®šin_shardingså’Œout_shardings
    logger.info("ğŸ“‹ 4.4: JITç¼–è¯‘åˆå§‹åŒ–å‡½æ•°ï¼ŒæŒ‡å®šin_shardingså’Œout_shardings...")
    jit_compile_start_time = time.time()
    def _init_fn(rng, params):
        return clean_init_fn(rng, params)
    
    # ğŸ’¯ æ ¹æœ¬æ€§ä¿®å¤ï¼šæƒé‡ä½œä¸ºå‚æ•°ä¼ å…¥ + donateé‡Šæ”¾61GBå†…å­˜ï¼
    logger.info("ğŸ”‘ æƒé‡å°†ä½œä¸ºJITå‚æ•°ä¼ å…¥ï¼Œä¸å†é€šè¿‡é—­åŒ…å ç”¨å†…å­˜")
    sharded_init_fn = jax.jit(
        _init_fn,
        in_shardings=(replicated_sharding, replicated_sharding),  # rngå’Œparamséƒ½å¤åˆ¶åˆ†ç‰‡
        out_shardings=train_state_sharding,  # è¾“å‡ºä½¿ç”¨FSDPåˆ†ç‰‡
        donate_argnums=(1,)  # ğŸ’¯ å…³é”®ï¼æèµ æƒé‡å‚æ•°å†…å­˜ï¼Œé‡Šæ”¾61GBï¼
    )
    jit_compile_time = time.time() - jit_compile_start_time
    logger.info(f"âœ… JITç¼–è¯‘å®Œæˆï¼Œè€—æ—¶: {jit_compile_time:.2f}s")
    
    # 4.4 è°ƒç”¨JITå‡½æ•°ï¼Œè®©JAXè‡ªåŠ¨åˆ†ç‰‡
    logger.info("ğŸ“‹ 4.5: è°ƒç”¨JITå‡½æ•°ï¼Œè‡ªåŠ¨åº”ç”¨FSDPåˆ†ç‰‡...")
    logger.info("ğŸ”‘ é€šè¿‡å›ºå®šRNGå’Œå…¨å±€åˆå§‹åŒ–å‡½æ•°ç¡®ä¿ä¸¤æ¬¡è°ƒç”¨çš„ç¡®å®šæ€§")
    logger.info("ğŸ’¯ donate_argnums=(1,)ç°åœ¨å¯ä»¥çœŸæ­£é‡Šæ”¾JAX pytreeçš„61GBå†…å­˜ï¼")
    jit_execution_start_time = time.time()
    with sharding.set_mesh(mesh):
        train_state = sharded_init_fn(rng, loaded_params_dict)
    jit_execution_time = time.time() - jit_execution_start_time
    logger.info(f"âœ… JITæ‰§è¡Œå®Œæˆï¼Œè€—æ—¶: {jit_execution_time:.2f}s")
    
    logger.info("âœ… FSDPåˆ†ç‰‡åˆå§‹åŒ–å®Œæˆï¼")
    jax.block_until_ready(train_state)  # ç¡®ä¿å®Œæˆ
    
    # ğŸ“Š å†…å­˜è¯Šæ–­ï¼šJITåˆå§‹åŒ–å
    after_jit_memory_gb = process.memory_info().rss / (1024**3)
    jit_memory_increase = after_jit_memory_gb - initial_memory_gb
    logger.info(f"ğŸ“Š JITåˆå§‹åŒ–åå†…å­˜: {after_jit_memory_gb:.1f}GB (æ€»å¢åŠ : {jit_memory_increase:.1f}GB)")
    
    # ğŸ§¹ å¼ºåˆ¶æ¸…ç†loaded_params_dictå†…å­˜ï¼Œé‡Šæ”¾61GBï¼
    logger.info("ğŸ§¹ å¼ºåˆ¶æ¸…ç†æƒé‡é¢„åŠ è½½å†…å­˜...")
    if 'loaded_params_dict' in locals() and loaded_params_dict is not None:
        del loaded_params_dict  # æ˜¾å¼åˆ é™¤å¼•ç”¨
        logger.info("âœ… loaded_params_dictå¼•ç”¨å·²åˆ é™¤")
    
    # å¼ºåˆ¶åƒåœ¾æ”¶é›†
    import gc
    gc.collect()  # Pythonåƒåœ¾æ”¶é›†
    
    # æ¸…ç†JAXç¼“å­˜
    jax.clear_caches()  # æ¸…ç†JAXå†…éƒ¨ç¼“å­˜
    
    # ç»™æ“ä½œç³»ç»Ÿæ—¶é—´å›æ”¶å†…å­˜
    import time
    time.sleep(1.0)  # ç­‰å¾…å†…å­˜å›æ”¶
    
    # ğŸ“Š å†…å­˜è¯Šæ–­ï¼šå†…å­˜æ¸…ç†å
    after_cleanup_memory_gb = process.memory_info().rss / (1024**3)
    cleanup_memory_freed = after_jit_memory_gb - after_cleanup_memory_gb
    final_memory_increase = after_cleanup_memory_gb - initial_memory_gb
    
    logger.info(f"ğŸ“Š å†…å­˜æ¸…ç†å: {after_cleanup_memory_gb:.1f}GB (é‡Šæ”¾: {cleanup_memory_freed:.1f}GB)")
    logger.info(f"ğŸ“Š æœ€ç»ˆå†…å­˜å¢é•¿: {final_memory_increase:.1f}GB (ä» {initial_memory_gb:.1f}GB â†’ {after_cleanup_memory_gb:.1f}GB)")
    
    if cleanup_memory_freed > 0:
        logger.info("âœ… å†…å­˜æ¸…ç†æˆåŠŸï¼å·²é‡Šæ”¾éƒ¨åˆ†å†…å­˜")
    else:
        logger.warning("âš ï¸  å†…å­˜æ¸…ç†æ•ˆæœæœ‰é™ï¼Œå¯èƒ½éœ€è¦å…¶ä»–æ–¹æ³•")
    
    # ğŸ” å…³é”®éªŒè¯ï¼šæ£€æŸ¥å„è®¾å¤‡ä¸Šçš„å®é™…åˆ†ç‰‡æƒ…å†µ
    logger.info("ğŸ” éªŒè¯å®é™…åˆ†ç‰‡æƒ…å†µ...")
    logger.info("=" * 80)
    
    try:
        # æ£€æŸ¥ä¸»è¦ç»„ä»¶çš„åˆ†ç‰‡æƒ…å†µ
        for component_name, component in [("Ï€â‚€å‚æ•°", train_state.pi0_params), 
                                         ("Ï€â‚€ä¼˜åŒ–å™¨", train_state.pi0_opt_state),
                                         ("Criticå‚æ•°", train_state.critic_params),
                                         ("Criticä¼˜åŒ–å™¨", train_state.critic_opt_state)]:
            if component is not None:
                logger.info(f"ğŸ” {component_name}åˆ†ç‰‡æƒ…å†µ:")
                
                # æ£€æŸ¥å…·æœ‰å¤§å‚æ•°çš„é¡¶å±‚å­—æ®µ
                sample_fields = []
                def collect_large_fields(path, value):
                    if hasattr(value, 'shape') and len(value.shape) > 0:
                        size = value.size if hasattr(value, 'size') else 0
                        if size > 1000:  # åªæŸ¥çœ‹å¤§å‚æ•°
                            sample_fields.append((jax.tree_util.keystr(path), value))
                    return value
                
                jax.tree_util.tree_map_with_path(collect_large_fields, component)
                
                # æ‰“å°å‰5ä¸ªå¤§å‚æ•°çš„åˆ†ç‰‡æƒ…å†µ
                for i, (path, param) in enumerate(sample_fields[:5]):
                    if hasattr(param, 'sharding'):
                        logger.info(f"  {path}: å…¨å±€{param.shape} -> åˆ†ç‰‡: {param.sharding}")
                        
                        # æ£€æŸ¥æœ¬åœ°å½¢çŠ¶ï¼ˆåªæ£€æŸ¥å‰ä¸¤ä¸ªè®¾å¤‡ï¼‰
                        if hasattr(param, 'addressable_shards') and len(param.addressable_shards) > 0:
                            for device_idx in range(min(2, len(param.addressable_shards))):
                                try:
                                    local_data = param.addressable_shards[device_idx].data
                                    local_shape = local_data.shape if hasattr(local_data, 'shape') else "N/A"
                                    logger.info(f"    è®¾å¤‡{device_idx}: {local_shape}")
                                except Exception as e:
                                    logger.info(f"    è®¾å¤‡{device_idx}: æ— æ³•è·å–å½¢çŠ¶ ({e})")
                    else:
                        logger.info(f"  {path}: å…¨å±€{param.shape} -> æ— åˆ†ç‰‡ä¿¡æ¯")
                        
                logger.info(f"  âœ… {component_name}å…±æœ‰{len(sample_fields)}ä¸ªå¤§å‚æ•°")
                logger.info("")
        
        logger.info("âœ… åˆ†ç‰‡éªŒè¯å®Œæˆ")
        
    except Exception as e:
        logger.warning(f"ğŸš¨ åˆ†ç‰‡éªŒè¯å¤±è´¥: {e}")
    
    logger.info("=" * 80)
    
    # **STEP 5: åˆ›å»ºè®­ç»ƒé…ç½®å’ŒJITå‡½æ•°**
    logger.info("ğŸ”„ STEP 5/5: åˆ›å»ºè®­ç»ƒé…ç½®å’ŒJITå‡½æ•°...")
    training_config = {
        'critic_weight': getattr(rl_config.acrlpd, 'critic_weight', 1.0),
        'actor_weight': getattr(rl_config.acrlpd, 'actor_weight', 1.0), 
        'bc_weight': getattr(rl_config.acrlpd, 'bc_loss_weight', 0.01),
        'alpha_weight': getattr(rl_config.acrlpd, 'alpha_weight', 1.0),
        'freeze_pi0_backbone': getattr(rl_config, 'freeze_pi0_backbone', False),
        'target_update_tau': getattr(rl_config.acrlpd, 'target_update_tau', 0.005)
    }
    
    def create_lazy_jit_train_step():
        """Create JIT training step only when actually needed to save memory."""
        return create_acrlpd_jit_train_step(
            mesh=mesh,
            data_sharding=data_sharding,
            train_state_sharding=train_state_sharding,
            config=training_config
        )
    
    logger.info("ğŸ‰ ACRLPD FSDPè®­ç»ƒç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸï¼ˆä¿®å¤ç‰ˆæœ¬ï¼šçœŸæ­£çš„FSDPåˆ†ç‰‡ï¼‰")
    log_train_state_info(train_state)
    
    return train_state, train_state_sharding, create_lazy_jit_train_step